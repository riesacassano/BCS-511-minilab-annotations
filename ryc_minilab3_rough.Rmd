---
title: 'Minilab 3: annotations'
author: "Riesa Cassano"
date: "4/10/2022"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
library(tidyverse)
library(modelr)
library(magrittr)
library(patchwork)
library(irr)
```

<!--First, load the data in long format.!-->
```{r load data, include=FALSE}
data_long <- as_tibble(read_csv('data/responses_binarized_long.csv'))

# convert exp_subject_id to a factor
data_long <- mutate(data_long, exp_subject_id = as.factor(exp_subject_id))
levels(data_long$exp_subject_id) <- seq(1,43)
```

<!--For easier handling, nest each run into one cell.!-->
```{r nest responses}
data <- data_long %>%
  group_by(exp_subject_id, scram_cond, stim_num, run) %>%
  nest(response_tbl = c(time,response)) #%>%
  #print()
```

<!--Looking at one example. The seconds are in the first column, the binary vector of responses is in the second column.!-->
```{r example vector, include=FALSE}
data$response_tbl[[1]]
data$response_tbl[[1]][[2]]
```

### Response rates 

Calculate response rates by summing over number of responses per run and dividing by 80 seconds (1.33 minutes).

```{r calculate response rates}
response_rate <- data_long %>%
  group_by(exp_subject_id, scram_cond, stim_num, run) %>%
  summarize(response_count = sum(response)) %>%
  mutate(response_rate = response_count / 1.33) #%>%
  #print()
```

#### Differences between subjects

Average over stimuli and runs to get an average response rate by subject.

```{r avg rate per subject}
p_avg_rate_subj <- response_rate %>%
  group_by(exp_subject_id) %>%
  summarize(mean_rate = mean(response_rate), sd_rate = sd(response_rate)) %>%
  #print() %>%
  
  ggplot(aes(x = exp_subject_id, y = mean_rate)) +
  geom_bar(stat = 'identity') +
  geom_errorbar(aes(ymin = mean_rate - sd_rate, ymax = mean_rate + sd_rate)) +
  labs(title = "Mean response rate per subject",
       x = "subject",
       y = "mean response rate (responses/minute)") +
  theme(axis.text.x = element_text(angle = -90, vjust = 0.5, hjust = 1))
  
p_avg_rate_subj
```

Visualizing differences across conditions: average over stimuli and runs in a condition to get an average response rate by subject per condition.

```{r avg rate per subject by condition, fig.height=6, fig.width=10}
p_avg_rate_subj_cond <- response_rate %>%
  group_by(exp_subject_id, scram_cond) %>%
  summarize(mean_rate = mean(response_rate), sd_rate = sd(response_rate)) %>%
  #print() %>%
  
  ggplot(aes(x = exp_subject_id, y = mean_rate)) +
  facet_wrap(vars(scram_cond), nrow=2, ncol=2) +
  geom_bar(stat = 'identity') +
  geom_errorbar(aes(ymin = mean_rate - sd_rate, ymax = mean_rate + sd_rate)) +
  labs(title = "Mean response rate per subject",
       x = "subject",
       y = "mean response rate (responses/minute)") +
  theme(axis.text.x = element_text(angle = -90, vjust = 0.5, hjust = 1))
  
p_avg_rate_subj_cond
```

It seems like there's more variability in response rate in the 1B and 2B conditions compared to the 8B and intact. One way to explore consistency across subjects is by correlating response rates by subjects across conditions. Subjects with higher rates in 1B are expected to have higher rates in intact relative to other subjects. In a linear model, a non-zero intercept would suggest an effect of condition on response rate.

```{r compare rates across conditions, fig.width=10}
response_rate_wide <- response_rate %>%
  group_by(exp_subject_id, scram_cond) %>%
  summarize(mean_rate = mean(response_rate)) %>%
  pivot_wider(names_from = scram_cond, values_from = mean_rate) #%>%
  #print()

p_8B_I <- ggplot(response_rate_wide, aes(x = intact, y = `8B`)) +
  geom_point() +
  geom_smooth(method=lm) +
  ylim(0,20)

p_2B_I <- ggplot(response_rate_wide, aes(x = intact, y = `2B`)) +
  geom_point() +
  geom_smooth(method=lm) +
  ylim(0,20)
  
p_1B_I <- ggplot(response_rate_wide, aes(x = intact, y = `1B`)) +
  geom_point() +
  geom_smooth(method=lm) +
  ylim(0,20)

p_8B_I + p_2B_I + p_1B_I
```

```{r linear models compare conditions}
summary(lm(`8B` ~ intact, response_rate_wide))
summary(lm(`2B` ~ intact, response_rate_wide))
summary(lm(`1B` ~ intact, response_rate_wide))
```

Response rates in intact explain the most variability in response rates in 8B (R^2 = 0.8653) and less variability in 2B (R^2 = 0.5044) and 1B (R^2 = 0.6032). This suggests that subjects are more consistent in rate between intact and 8B. One explanation for rate in intact begin a worse predictor of rate in 2B and 1B is that subjects' behavior changes between the more scrambled conditions and less scrambled conditions. 

In each comparison, the intercept is positive, indicating that there is an effect of condition on response rate and that subjects' response rates in the more scrambled conditions are higher than in the intact condition. Slope estimates are close to 1.0, as expected. For the intact to 1B comparison, slope is slightly larger than 1.0. This seems to be driven by some subjects with lower rates in intact (between 1 and 5 responses per minute) having higher rates than expected in 1B (around 8 to 12 responses per minute).

Follow-up: are subjects consistent between 2B and 1B?

```{r 2B vs 1B}
p_1B_2B <- ggplot(response_rate_wide, aes(x = `2B`, y = `1B`)) +
  geom_point() +
  geom_smooth(method=lm) +
  ylim(0,20)
p_1B_2B

summary(lm(`1B` ~ `2B`, response_rate_wide))
```

Responses rates in 2B explain almost as much variability in 1B (R^2 = 0.8047) as intact does in 8B. The intercept is not different from 0.0 and the slope is very close to 1.0. This suggests that subjects' response rates are consistent between 2B and 1B. This could imply that subjects have an intrinsic response rate that is not related to the stimulus.

Another follow-up: what if the "outlier" is removed? There is one subject whose response rate in intact is around 12.5.

```{r compare rates across conditions no outlier, fig.width=10}
response_rate_wide_no_out <- response_rate %>%
  group_by(exp_subject_id, scram_cond) %>%
  summarize(mean_rate = mean(response_rate)) %>%
  pivot_wider(names_from = scram_cond, values_from = mean_rate) %>%
  filter(intact < 10)

p_8B_I <- ggplot(response_rate_wide_no_out, aes(x = intact, y = `8B`)) +
  geom_point() +
  geom_smooth(method=lm) +
  ylim(0,15)

p_2B_I <- ggplot(response_rate_wide_no_out, aes(x = intact, y = `2B`)) +
  geom_point() +
  geom_smooth(method=lm) +
  ylim(0,15)
  
p_1B_I <- ggplot(response_rate_wide_no_out, aes(x = intact, y = `1B`)) +
  geom_point() +
  geom_smooth(method=lm) +
  ylim(0,15)

p_8B_I + p_2B_I + p_1B_I
```

```{r linear models compare conditions no outlier}
summary(lm(`8B` ~ intact, response_rate_wide_no_out))
summary(lm(`2B` ~ intact, response_rate_wide_no_out))
summary(lm(`1B` ~ intact, response_rate_wide_no_out))
```

It seems like that "outlier" was artificially raising the R^2 values. This is an interesting result, but doesn't motivate exclusion of this subject necessarily.

\newpage
#### Differences across stimuli and conditions

Average over subjects to get an average response rate by stimulus.

```{r avg rate per stimulus}
p_avg_rate_stim <- response_rate %>%
  mutate(scram_cond = as.factor(scram_cond),
         stim_num = as.factor(stim_num)) %>%
  group_by(scram_cond, stim_num) %>%
  summarize(mean_rate = mean(response_rate), sd_rate = sd(response_rate)) %>%
  #print() %>%
  
  ggplot(aes(x = scram_cond, y = mean_rate, fill = stim_num)) +
  geom_bar(stat = 'identity', position = "dodge") +
  geom_errorbar(aes(ymin = mean_rate - sd_rate, ymax = mean_rate + sd_rate),
                position = "dodge") +
  labs(title = "Mean response rate per condition and stimulus number",
       x = "condition",
       fill = "stimulus number",
       y = "mean response rate (responses/minute)")


p_avg_rate_stim
```

Averaging over stimulus number to just look at average response rate by condition.
```{r avg rate per condition}
p_avg_rate_cond <- response_rate %>%
  mutate(scram_cond = as.factor(scram_cond)) %>%
  group_by(scram_cond) %>%
  summarize(mean_rate = mean(response_rate), sd_rate = sd(response_rate)) %>%
  #print() %>%
  
  ggplot(aes(x = scram_cond, y = mean_rate)) +
  geom_bar(stat = 'identity') +
  geom_errorbar(aes(ymin = mean_rate - sd_rate, ymax = mean_rate + sd_rate),
                width = 0.5) +
  labs(title = "Mean response rate per condition",
       x = "condition",
       y = "mean response rate (responses/minute)")

p_avg_rate_cond
```

Based on this plot, there seems to be no difference in mean response rates between 1B and 2B and between 8B and Intact, but there appears to be a difference between the more scrambled conditions (1B and 2B) and the less scrambled conditions (8B and Intact). To test this, let's run a paired t-test (by subject) for each of those observations. To do this by subject, we have to average over all stimuli and runs for each condition for each subject.

```{r avg rate per cond per subject}
avg_rate_cond_subject <- response_rate %>%
  mutate(scram_cond = as.factor(scram_cond)) %>%
  group_by(exp_subject_id, scram_cond) %>%
  summarize(mean_rate = mean(response_rate)) #%>%
  #print()
  
p_avg_rate_cond_subject <- avg_rate_cond_subject %>%
  ggplot(aes(x = scram_cond, y = mean_rate)) +
  geom_violin() +
  labs(title = "Mean response rate per condition",
       x = "condition",
       y = "mean response rate (responses/minute)")

p_avg_rate_cond_subject
```

The violin plots are just a different way of visualizing this data. Are these data approximately normally distributed?

```{r test for normality}
dist.1B <- filter(avg_rate_cond_subject, scram_cond == '1B')$mean_rate
dist.2B <- filter(avg_rate_cond_subject, scram_cond == '2B')$mean_rate
dist.8B <- filter(avg_rate_cond_subject, scram_cond == '8B')$mean_rate
dist.intact <- filter(avg_rate_cond_subject, scram_cond == 'intact')$mean_rate

shapiro.test(dist.1B)
shapiro.test(dist.2B)
shapiro.test(dist.8B)
shapiro.test(dist.intact)
```

Since none of these distributions are normally distributed, a non-parametric test is appropriate - specifically a paired samples Wilcoxon test (aka Wilcoxon signed rank test). We expect that the difference between 1B and 2B is not significant and that the difference between 8B and intact is not significant.

```{r Wilcoxon test between conds, warning=FALSE}
wilcox.test(dist.1B, dist.2B, paired = TRUE)
wilcox.test(dist.8B, dist.intact, paired = TRUE)
```

The difference between 2B and 1B is not significant. However, the difference between 8B and intact is significant. *Warnings from Wilcoxon test: cannot compute exact p-value with ties/zeros.*

<!-- Finally, let's group the conditions into more scrambled (2B, 1B) and less scrambled (8B, intact). Although there appears to be a difference between 8B and intact, this grouping makes sense from a music theory perspective - the more scrambled conditions don't have intact phrases and the less scrambled conditions do. !--> 

\newpage
## Inter-subject agreement

First, let's visualize timing of responses for one stimulus to get a sense for how matched the subject responses might be using a raster-like representation. For this, we'll look at the second run of the first stimulus of the Intact condition.

```{r visualize I_1 all responses}
p_I_1_r2 <- data_long %>%
  filter(scram_cond == 'intact', stim_num == 1, run == 2) %>%
  
  ggplot(aes(x = time, y = exp_subject_id, fill = response)) +
  geom_tile(color = "black") +
  labs(x = "seconds", y = "subject")
  
p_I_1_r2
```

There appears to be a general agreement around 30 seconds and 70 seconds for this stimulus. To get a rough idea of where this agreement exists for each of the stimuli we'll simply plot the sum over subject responses in run 2.

```{r visualize sum of responses, fig.height=5, fig.width=10}
p_sum_resp <- data_long %>%
  group_by(scram_cond, stim_num, run, time) %>%
  summarize(sum_resp = sum(response)) %>%
  filter(run == 2) %>%
  
  ggplot(aes(x = time, y = scram_cond, fill = sum_resp)) +
  facet_grid(cols = vars(stim_num)) +
  geom_tile(color = "black") +
  labs(x = "seconds", y = "condition")

p_sum_resp
```

As expected, there are moments in the intact and 8B stimuli with stronger subject agreement. In 2B and 1B, the responses seem much more washed out, indicating much less agreement.

#### Bootstrap intersubject correlation

Intersubject correlation is the correlation between one subject's time series of responses and the average of all other subjects' time series of responses.

```{r ISC functions, include=FALSE}
compute_isc <- function(data, stim){
  # stim contains c(condition, stimulus number, run)
  
  n_subj <- length(levels(data$exp_subject_id))
  isc_vals <- vector(length=n_subj)
  
  # loop through all subjects
  for (sub in seq(n_subj)){ # this works because subjects are labeled 1 to 43
    this_sub_data <- data %>%
      filter(exp_subject_id == sub,
             scram_cond == stim[1],
             stim_num == stim[2],
             run == stim[3])
    
    # for testing bootstrap, permute
    #perms <- permute(this_sub_data, 1, response)
    
    avg_others_data <- data %>%
      filter(exp_subject_id != sub,
             scram_cond == stim[1],
             stim_num == stim[2],
             run == stim[3]) %>%
      group_by(time) %>%
      summarize(avg_resp = mean(response))
    
    isc_vals[sub] <- cor(this_sub_data$response,avg_others_data$avg_resp)
    #isc_vals[sub] <- cor(this_sub_data$response[perms$perm[[1]]$idx],
    #                     avg_others_data$avg_resp)
    
  }
  
  return(mean(isc_vals))
  
}

compute_null_dist <- function(data, stim, n_samples) {
  # create array (n_subj x n_samples)
  n_subj <- length(levels(data$exp_subject_id))
  null_dist <- matrix(0, nrow=n_subj, ncol=n_samples)
  
  # loop through all subjects
  for (sub in seq(n_subj)){
    # compute average over other subjects
    avg_others_data <- data %>%
      filter(exp_subject_id != sub,
             scram_cond == stim[1],
             stim_num == stim[2],
             run == stim[3]) %>%
      group_by(time) %>%
      summarize(avg_resp = mean(response))
    
    # get this subject's data
    this_sub_data <- data %>%
      filter(exp_subject_id == sub,
             scram_cond == stim[1],
             stim_num == stim[2],
             run == stim[3])
    
    # create permutations
    perms <- permute(this_sub_data, n_samples, response)
    
    # loop through number of samples
    for (n in seq(n_samples)){
      null_dist[sub,n] <- cor(this_sub_data$response[perms$perm[[n]]$idx],
                              avg_others_data$avg_resp)
      
    }
  
  }

  return(colMeans(null_dist))
  
}
  

compare_true_to_null <- function(data, stim, n_samples){
  # compute true ISC
  true_avg_isc <- compute_isc(data, stim)
  print(true_avg_isc)
  
  # perform n permutations
  null_dist <- compute_null_dist(data, stim, n_samples)
  print(null_dist)
  
  # compute z-score of true value in comparison to null distribution
  print(pnorm(true_avg_isc, mean=mean(null_dist), sd=sd(null_dist)))
  
}

# test
test_stim <- c('intact',1,2) 
#compare_true_to_null(data_long,test_stim,100)

```

Since the response vectors are binary, intersubject correlation might not be the best measure to use.

#### Intersubject reliability: Cohen's kappa


## Predicting responses with the ground truth

```{r load ground truths}
gt_periodic <- as_tibble(read_csv('data/ground_truth_phrase_boundaries_periodic.csv'))
#print(gt_periodic)

gt_tracked <- as_tibble(read_csv('data/ground_truth_phrase_boundaries_tracked.csv'))
#print(gt_tracked)

# get ground truths for intact and 8B stimuli (it's the same)
gt_less_scram <- filter(gt_periodic, scram_cond != '2B', scram_cond != '1B')
#print(gt_less_scram)

# nest
gt_less_scram <- gt_less_scram %>%
  group_by(scram_cond, stim_num) %>%
  nest(response_tbl = c(time,response)) %>%
  print()
```

#### Less scrambled conditions: intact and 8B

```{r kappa helper function}
kappa_helper <- function(data_tbl, gt_ind){
  data <- data_tbl$response
  ground_truth <- gt_less_scram$response_tbl[[gt_ind]]$response
  
  m <- matrix(c(data,ground_truth), ncol=2)
  kappa_results <- kappa2(m)
  result_list <- list('kappa.value' = kappa_results$value,
                      'p.value' = kappa_results$p.value)
  return(result_list)
}

test_data <- data$response_tbl[[1]]
test_gt <- 2
result <- kappa_helper(test_data, test_gt)
print(result$kappa.value)
print(result$p.value)
```

```{r perform IRR on less scrambled conditions, one subject test, fig.height=1.5, fig.width=10}
data_less_scram <- data %>%
  # filter out more scrambled conditions and run 1 data
  filter(scram_cond != '2B', scram_cond != '1B', run == 2) %>% 
  # test with one subject
  filter(exp_subject_id == '18') %>%
  
  mutate(
    gt_tbl_ind = case_when(
      scram_cond == '8B' & stim_num == 1 ~ 1,
      scram_cond == '8B' & stim_num == 2 ~ 2,
      scram_cond == '8B' & stim_num == 3 ~ 3,
      scram_cond == 'intact' & stim_num == 1 ~ 4,
      scram_cond == 'intact' & stim_num == 2 ~ 5,
      scram_cond == 'intact' & stim_num == 3 ~ 6
    )
  ) %>%
  
  mutate(gt_tbl_ind = as.integer(gt_tbl_ind)) %>%
  
  #mutate(kappa_value = kappa_helper(response_tbl,gt_tbl_ind)$kappa.value,
  #       p_value = kappa_helper(response_tbl,gt_tbl_ind)$p.value) %>%

  print()

data_less_scram$kappa <- numeric(nrow(data_less_scram))
data_less_scram$p <- numeric(nrow(data_less_scram))

for (row in seq(nrow(data_less_scram))){
  these_results <- kappa_helper(data_less_scram$response_tbl[[row]],
                                data_less_scram$gt_tbl_ind[[row]])
  data_less_scram$kappa[[row]] <- these_results$kappa.value
  data_less_scram$p[[row]] <- these_results$p.value
}

print(data_less_scram)

# visualize intact 1 and 8B 1
resp_i1_tbl <- data_less_scram$response_tbl[[4]]
gt_i1_tbl <- gt_less_scram$response_tbl[[4]]

resp_i1 <- ggplot(resp_i1_tbl, 
                  aes(x=time, y=1, fill=response)) +
  geom_tile() +
  ylab('intact 1 responses')
gt_i1 <- ggplot(gt_i1_tbl, 
                aes(x=time, y=1, fill=response)) +
  geom_tile() +
  ylab('intact 1 ground truth')

resp_i1
gt_i1
print(data_less_scram$p[[4]])


resp_8B1_tbl <- data_less_scram$response_tbl[[3]]
gt_8B1_tbl <- gt_less_scram$response_tbl[[1]]

resp_8B1 <- ggplot(resp_8B1_tbl, 
                   aes(x=time, y=1, fill=response)) +
  geom_tile() +
  ylab('8B 1 responses')
gt_8B1 <- ggplot(gt_8B1_tbl, 
                 aes(x=time, y=1, fill=response)) +
  geom_tile() +
  ylab('8B 1 ground truth')

resp_8B1
gt_8B1
print(data_less_scram$p[[3]])

```

In the intact 1 stimulus, this subject marked the last ground truth boundary to a second. This gives a significant p-value for Cohen's kappa. In the 8B 1 stimulus, the subject seemed to mark three of the four boundaries, but was off by a few seconds. This gives a very poor Cohen's kappa result. 

```{r visualize intact 3, fig.height=1.5, fig.width=10}
resp_i3_tbl <- data_less_scram$response_tbl[[2]]
gt_i3_tbl <- gt_less_scram$response_tbl[[6]]

resp_i3 <- ggplot(resp_i3_tbl, 
                  aes(x=time, y=1, fill=response)) +
  geom_tile() +
  ylab('intact 3 responses')
gt_i3 <- ggplot(gt_i3_tbl, 
                aes(x=time, y=1, fill=response)) +
  geom_tile() +
  ylab('intact 3 ground truth')

resp_i3
gt_i3
print(data_less_scram$p[[2]])
```

The subject did not respond in Intact 3. Thus Cohen's kappa is meaningless.

For each of the stimuli, calculate Cohen's kappa at various lags: (-3,5). *Struggling in `Untitled.Rmd`, want to do this in python*


### For the writeup

Visualize responses, raster style (run 1 and run 2)
- sums (run 1 and run 2?)

```{r visualize all responses, fig.height=15, fig.width=15}
p_r1 <- data_long %>%
  filter(run == 1) %>%
  
  ggplot(aes(x = time, y = exp_subject_id, fill = response)) +
  facet_grid(rows = vars(scram_cond), cols = vars(stim_num)) +
  geom_tile(color = "black") +
  labs(x = "seconds", y = "subject", title = "Run 1") +
  theme(text = element_text(size = 20),
        axis.text.y = element_text(size = 7))
  
p_r1
#ggsave("plots/raster_resp_run1.pdf", plot = p_r1)

p_r2 <- data_long %>%
  filter(run == 2) %>%
  
  ggplot(aes(x = time, y = exp_subject_id, fill = response)) +
  facet_grid(rows = vars(scram_cond), cols = vars(stim_num)) +
  geom_tile(color = "black") +
  labs(x = "seconds", y = "subject", title = "Run 2") +
  theme(text = element_text(size = 20),
        axis.text.y = element_text(size = 7))
  
p_r2
#ggsave("plots/raster_resp_run2.pdf", plot = p_r2)
```

Visualize sums over subjects
```{r visualize sums, fig.height=5, fig.width=10}
p_sum_resp1 <- data_long %>%
  group_by(scram_cond, stim_num, run, time) %>%
  summarize(sum_resp = sum(response)) %>%
  filter(run == 1) %>%
  
  ggplot(aes(x = time, y = scram_cond, fill = sum_resp)) +
  facet_grid(cols = vars(stim_num)) +
  geom_tile(color = "black") +
  labs(x = "seconds", y = "condition", title = "Run 1")

p_sum_resp1
#ggsave("plots/sum_resp_run1.pdf", plot = p_sum_resp1)

p_sum_resp2 <- data_long %>%
  group_by(scram_cond, stim_num, run, time) %>%
  summarize(sum_resp = sum(response)) %>%
  filter(run == 2) %>%
  
  ggplot(aes(x = time, y = scram_cond, fill = sum_resp)) +
  facet_grid(cols = vars(stim_num)) +
  geom_tile(color = "black") +
  labs(x = "seconds", y = "condition", title = "Run 2")

p_sum_resp2
#ggsave("plots/sum_resp_run2.pdf", plot = p_sum_resp2)
```


#### Comparing lags across conditions

then `lm(kappa ~ cond)` for each lag, then model comparison with ANOVA
```{r load lag kappa data}
d_kappa <- as_tibble(read_csv('data/lag_kappa_values.csv'))

# code stuff as factors
#d_kappa$scram_cond
d_kappa$lag <- as.factor(d_kappa$lag)
print(d_kappa)
```

Plot kappa values from all four conditions across all subjects, runs, stimulus numbers, and lags.

```{r plot periodic}
p_periodic <- d_kappa %>%
  filter(gt_type != 'tracked') %>% # leave 'actual' (I, 8B) and 'periodic' (2B, 1B)
  
  ggplot(aes(x = scram_cond, y = kappa, color = lag)) +
  geom_point(position = 'jitter', alpha = 0.3) +
  geom_smooth(aes(group = lag), method = lm) +
  labs(x = 'condition')
  
p_periodic
#ggsave("plots/lag_kappa_all_periodic.png", plot = p_periodic)
  
```

```{r plot tracked}
p_tracked <- d_kappa %>%
  filter(gt_type != 'periodic') %>% # leave 'actual' (I, 8B) and 'tracked' (2B, 1B)
  
  ggplot(aes(x = scram_cond, y = kappa, color = lag)) +
  geom_point(position = 'jitter', alpha = 0.3) +
  geom_smooth(aes(group = lag), method = lm) +
  labs(x = 'condition')
  
p_tracked
#ggsave("plots/lag_kappa_all_tracked.png", plot = p_tracked)
  
```

```{r linear models for periodic}
d_kappa_periodic <- filter(d_kappa, gt_type != 'tracked')

lm_cond <- lm(kappa ~ scram_cond, data=d_kappa_periodic)
summary(lm_cond)
lm_wo_int <- lm(kappa ~ scram_cond + lag, data=d_kappa_periodic)
summary(lm_wo_int)
lm_w_int <- lm(kappa ~ scram_cond + lag + scram_cond*lag, data=d_kappa_periodic)
summary(lm_w_int)
anova(lm_wo_int, lm_w_int, test = 'Chisq')
```

```{r linear models for tracked}
d_kappa_tracked <- filter(d_kappa, gt_type != 'periodic')

lm_cond <- lm(kappa ~ scram_cond, data=d_kappa_tracked)
summary(lm_cond)
lm_wo_int <- lm(kappa ~ scram_cond + lag, data=d_kappa_tracked)
summary(lm_wo_int)
lm_w_int <- lm(kappa ~ scram_cond + lag + scram_cond*lag, data=d_kappa_tracked)
summary(lm_w_int)
anova(lm_wo_int, lm_w_int, test = 'Chisq')
```
